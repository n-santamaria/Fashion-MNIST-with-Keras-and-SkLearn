{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4747cdc8",
   "metadata": {},
   "source": [
    "# Fashion MNIST with SkLearn and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e61d5",
   "metadata": {},
   "source": [
    "Approach:-\n",
    "1. Load the data and audit/visualize\n",
    "2. Split the data\n",
    "    - X and Y\n",
    "    - Train and Test\n",
    "3. Using SkLearn API\n",
    "    - Single Layer Perceptron\n",
    "    - Multi Layer Perceptron\n",
    "4. Using Keras API\n",
    "    - Model: Sequential/Functional\n",
    "    - Layers: Dense Layer (Hidden Layers)\n",
    "    - Compile the model (optimizers, loss, metrics)\n",
    "    - Fit the model (input data, validation data, epochs/iterations, batch_size, verbose)\n",
    "5. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77be49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 497.6 MB 3.0 kB/s  eta 0:00:01     |███████████████████████████▋    | 430.0 MB 7.5 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/nvl/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nvl/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/nvl/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/nvl/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nvl/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/nvl/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nvl/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nvl/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=ec49163d3e20584275ba94369e3eb0ac2d2fcc7f2813a416803b279581734ccd\n",
      "  Stored in directory: /home/nvl/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbc336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 14:29:54.854998: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-25 14:29:54.855096: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a389f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (60000, 785)\n",
      "Test shape (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('archive/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('archive/fashion-mnist_test.csv')\n",
    "print('Train shape', train.shape)\n",
    "print('Test shape', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7f5322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6666dafd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = [\"pixel{}\".format(pixel_num) for pixel_num in range(1,785)]\n",
    "row_to_examine = 1\n",
    "image_data = np.reshape(train[features][row_to_examine: row_to_examine + 1].to_numpy(), (28,28))\n",
    "plt.imshow(image_data, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb2ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (60000, 784)\n",
      "y shape (60000,)\n",
      "X_train shape (48000, 784)\n",
      "X_test shape (12000, 784)\n",
      "y_train shape (48000,)\n",
      "y_test shape (12000,)\n"
     ]
    }
   ],
   "source": [
    "X = train.drop('label', axis=1)\n",
    "y = train['label']\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print('X_train shape', X_train.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_train shape', y_train.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b9f6a",
   "metadata": {},
   "source": [
    "## Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84eb8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes = (32,32,32), verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ab412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.97338410\n",
      "Iteration 2, loss = 0.88484387\n",
      "Iteration 3, loss = 0.71454163\n",
      "Iteration 4, loss = 0.63208697\n",
      "Iteration 5, loss = 0.58560480\n",
      "Iteration 6, loss = 0.55299731\n",
      "Iteration 7, loss = 0.52147866\n",
      "Iteration 8, loss = 0.50880551\n",
      "Iteration 9, loss = 0.48849912\n",
      "Iteration 10, loss = 0.47604222\n",
      "Iteration 11, loss = 0.45798296\n",
      "Iteration 12, loss = 0.45715278\n",
      "Iteration 13, loss = 0.45058566\n",
      "Iteration 14, loss = 0.43661602\n",
      "Iteration 15, loss = 0.42515632\n",
      "Iteration 16, loss = 0.41869205\n",
      "Iteration 17, loss = 0.41338642\n",
      "Iteration 18, loss = 0.40933760\n",
      "Iteration 19, loss = 0.40276817\n",
      "Iteration 20, loss = 0.39744053\n",
      "Iteration 21, loss = 0.39116901\n",
      "Iteration 22, loss = 0.38894379\n",
      "Iteration 23, loss = 0.38659121\n",
      "Iteration 24, loss = 0.38670718\n",
      "Iteration 25, loss = 0.37740884\n",
      "Iteration 26, loss = 0.37284102\n",
      "Iteration 27, loss = 0.37008438\n",
      "Iteration 28, loss = 0.36864463\n",
      "Iteration 29, loss = 0.35998488\n",
      "Iteration 30, loss = 0.35469119\n",
      "Iteration 31, loss = 0.35387719\n",
      "Iteration 32, loss = 0.35424203\n",
      "Iteration 33, loss = 0.34336215\n",
      "Iteration 34, loss = 0.34414914\n",
      "Iteration 35, loss = 0.33909134\n",
      "Iteration 36, loss = 0.34052167\n",
      "Iteration 37, loss = 0.33222778\n",
      "Iteration 38, loss = 0.33700289\n",
      "Iteration 39, loss = 0.33244002\n",
      "Iteration 40, loss = 0.32651004\n",
      "Iteration 41, loss = 0.32646516\n",
      "Iteration 42, loss = 0.32082013\n",
      "Iteration 43, loss = 0.32128744\n",
      "Iteration 44, loss = 0.31729644\n",
      "Iteration 45, loss = 0.31487511\n",
      "Iteration 46, loss = 0.31358053\n",
      "Iteration 47, loss = 0.32381570\n",
      "Iteration 48, loss = 0.31461147\n",
      "Iteration 49, loss = 0.30535785\n",
      "Iteration 50, loss = 0.30462842\n",
      "Iteration 51, loss = 0.30681533\n",
      "Iteration 52, loss = 0.30561351\n",
      "Iteration 53, loss = 0.29971240\n",
      "Iteration 54, loss = 0.29979819\n",
      "Iteration 55, loss = 0.30004456\n",
      "Iteration 56, loss = 0.29622039\n",
      "Iteration 57, loss = 0.29248851\n",
      "Iteration 58, loss = 0.29615951\n",
      "Iteration 59, loss = 0.29629433\n",
      "Iteration 60, loss = 0.29333595\n",
      "Iteration 61, loss = 0.29619360\n",
      "Iteration 62, loss = 0.29132072\n",
      "Iteration 63, loss = 0.29269092\n",
      "Iteration 64, loss = 0.28955845\n",
      "Iteration 65, loss = 0.30148608\n",
      "Iteration 66, loss = 0.28953196\n",
      "Iteration 67, loss = 0.28500130\n",
      "Iteration 68, loss = 0.28617818\n",
      "Iteration 69, loss = 0.28227964\n",
      "Iteration 70, loss = 0.28704946\n",
      "Iteration 71, loss = 0.28108490\n",
      "Iteration 72, loss = 0.28405056\n",
      "Iteration 73, loss = 0.27874422\n",
      "Iteration 74, loss = 0.28419024\n",
      "Iteration 75, loss = 0.27596917\n",
      "Iteration 76, loss = 0.27864596\n",
      "Iteration 77, loss = 0.27452701\n",
      "Iteration 78, loss = 0.27756373\n",
      "Iteration 79, loss = 0.28208544\n",
      "Iteration 80, loss = 0.27439716\n",
      "Iteration 81, loss = 0.27302726\n",
      "Iteration 82, loss = 0.27342999\n",
      "Iteration 83, loss = 0.27307337\n",
      "Iteration 84, loss = 0.27419880\n",
      "Iteration 85, loss = 0.27200618\n",
      "Iteration 86, loss = 0.27052912\n",
      "Iteration 87, loss = 0.26998940\n",
      "Iteration 88, loss = 0.27179075\n",
      "Iteration 89, loss = 0.26956008\n",
      "Iteration 90, loss = 0.26798610\n",
      "Iteration 91, loss = 0.26472999\n",
      "Iteration 92, loss = 0.26627970\n",
      "Iteration 93, loss = 0.26616155\n",
      "Iteration 94, loss = 0.25970102\n",
      "Iteration 95, loss = 0.25540773\n",
      "Iteration 96, loss = 0.26450621\n",
      "Iteration 97, loss = 0.26383985\n",
      "Iteration 98, loss = 0.27094537\n",
      "Iteration 99, loss = 0.26607368\n",
      "Iteration 100, loss = 0.25299837\n",
      "Iteration 101, loss = 0.25472035\n",
      "Iteration 102, loss = 0.25661287\n",
      "Iteration 103, loss = 0.25419154\n",
      "Iteration 104, loss = 0.25837552\n",
      "Iteration 105, loss = 0.25252006\n",
      "Iteration 106, loss = 0.25111957\n",
      "Iteration 107, loss = 0.25167183\n",
      "Iteration 108, loss = 0.25061387\n",
      "Iteration 109, loss = 0.25003112\n",
      "Iteration 110, loss = 0.24417819\n",
      "Iteration 111, loss = 0.24482936\n",
      "Iteration 112, loss = 0.25370798\n",
      "Iteration 113, loss = 0.24952768\n",
      "Iteration 114, loss = 0.24852409\n",
      "Iteration 115, loss = 0.24759654\n",
      "Iteration 116, loss = 0.24245019\n",
      "Iteration 117, loss = 0.25095682\n",
      "Iteration 118, loss = 0.25168741\n",
      "Iteration 119, loss = 0.24583663\n",
      "Iteration 120, loss = 0.23996119\n",
      "Iteration 121, loss = 0.24237682\n",
      "Iteration 122, loss = 0.24913714\n",
      "Iteration 123, loss = 0.24657152\n",
      "Iteration 124, loss = 0.24150762\n",
      "Iteration 125, loss = 0.23539487\n",
      "Iteration 126, loss = 0.24014459\n",
      "Iteration 127, loss = 0.23840558\n",
      "Iteration 128, loss = 0.23944576\n",
      "Iteration 129, loss = 0.24132634\n",
      "Iteration 130, loss = 0.23631238\n",
      "Iteration 131, loss = 0.23643234\n",
      "Iteration 132, loss = 0.23765413\n",
      "Iteration 133, loss = 0.23241684\n",
      "Iteration 134, loss = 0.23144726\n",
      "Iteration 135, loss = 0.24023920\n",
      "Iteration 136, loss = 0.23896640\n",
      "Iteration 137, loss = 0.24117443\n",
      "Iteration 138, loss = 0.23595042\n",
      "Iteration 139, loss = 0.23231017\n",
      "Iteration 140, loss = 0.22984200\n",
      "Iteration 141, loss = 0.23356582\n",
      "Iteration 142, loss = 0.22823891\n",
      "Iteration 143, loss = 0.23548011\n",
      "Iteration 144, loss = 0.23951390\n",
      "Iteration 145, loss = 0.23114700\n",
      "Iteration 146, loss = 0.23280129\n",
      "Iteration 147, loss = 0.23321204\n",
      "Iteration 148, loss = 0.22825030\n",
      "Iteration 149, loss = 0.23338829\n",
      "Iteration 150, loss = 0.22452166\n",
      "Iteration 151, loss = 0.23034276\n",
      "Iteration 152, loss = 0.23334296\n",
      "Iteration 153, loss = 0.23460599\n",
      "Iteration 154, loss = 0.23175903\n",
      "Iteration 155, loss = 0.22255761\n",
      "Iteration 156, loss = 0.22681062\n",
      "Iteration 157, loss = 0.22611392\n",
      "Iteration 158, loss = 0.21891935\n",
      "Iteration 159, loss = 0.22744494\n",
      "Iteration 160, loss = 0.22145456\n",
      "Iteration 161, loss = 0.22648428\n",
      "Iteration 162, loss = 0.23407510\n",
      "Iteration 163, loss = 0.22325073\n",
      "Iteration 164, loss = 0.21982304\n",
      "Iteration 165, loss = 0.22210295\n",
      "Iteration 166, loss = 0.21802589\n",
      "Iteration 167, loss = 0.22480295\n",
      "Iteration 168, loss = 0.22494511\n",
      "Iteration 169, loss = 0.22318579\n",
      "Iteration 170, loss = 0.22242504\n",
      "Iteration 171, loss = 0.22172368\n",
      "Iteration 172, loss = 0.22161012\n",
      "Iteration 173, loss = 0.21766648\n",
      "Iteration 174, loss = 0.22301529\n",
      "Iteration 175, loss = 0.22112588\n",
      "Iteration 176, loss = 0.22139472\n",
      "Iteration 177, loss = 0.22316127\n",
      "Iteration 178, loss = 0.22261509\n",
      "Iteration 179, loss = 0.22299439\n",
      "Iteration 180, loss = 0.22165303\n",
      "Iteration 181, loss = 0.21263297\n",
      "Iteration 182, loss = 0.21427036\n",
      "Iteration 183, loss = 0.22020394\n",
      "Iteration 184, loss = 0.22876874\n",
      "Iteration 185, loss = 0.21935812\n",
      "Iteration 186, loss = 0.21300560\n",
      "Iteration 187, loss = 0.21324247\n",
      "Iteration 188, loss = 0.21814174\n",
      "Iteration 189, loss = 0.21677361\n",
      "Iteration 190, loss = 0.21722244\n",
      "Iteration 191, loss = 0.21784171\n",
      "Iteration 192, loss = 0.20834420\n",
      "Iteration 193, loss = 0.21673995\n",
      "Iteration 194, loss = 0.21486024\n",
      "Iteration 195, loss = 0.21659839\n",
      "Iteration 196, loss = 0.21949371\n",
      "Iteration 197, loss = 0.22050328\n",
      "Iteration 198, loss = 0.20888400\n",
      "Iteration 199, loss = 0.21664357\n",
      "Iteration 200, loss = 0.21267197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvl/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 32, 32), verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6895a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40362fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(actual, predicted):\n",
    "    cm_mlp = confusion_matrix(actual, predicted)\n",
    "    acc_score = accuracy_score(actual, predicted)\n",
    "    class_report_mlp = classification_report(actual, predicted)\n",
    "    print('Accuracy:', acc_score)\n",
    "    print('\\nConfusion Matrix:\\n\\n', cm_mlp)\n",
    "    print('\\nClassification Report:', class_report_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e77ab93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8591666666666666\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[ 993    2   20   24    3    2  137    0    8    0]\n",
      " [   6 1138    2   28    6    0    4    0    5    0]\n",
      " [  14    1  943   17  150    0   74    0    5    0]\n",
      " [  54    8    9 1094   63    0   28    0    4    0]\n",
      " [   1    0   78   48  998    0   81    0    2    0]\n",
      " [   2    1    3    1    2 1122    2   18    5   32]\n",
      " [ 182    5  121   23  142    0  710    0   12    0]\n",
      " [   0    0    0    0    0   31    0 1013    5  111]\n",
      " [   7    2    2    2   14    1   33    0 1143    6]\n",
      " [   0    0    0    0    1   18    0   21    1 1156]]\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1189\n",
      "           1       0.98      0.96      0.97      1189\n",
      "           2       0.80      0.78      0.79      1204\n",
      "           3       0.88      0.87      0.88      1260\n",
      "           4       0.72      0.83      0.77      1208\n",
      "           5       0.96      0.94      0.95      1188\n",
      "           6       0.66      0.59      0.63      1195\n",
      "           7       0.96      0.87      0.92      1160\n",
      "           8       0.96      0.94      0.95      1210\n",
      "           9       0.89      0.97      0.92      1197\n",
      "\n",
      "    accuracy                           0.86     12000\n",
      "   macro avg       0.86      0.86      0.86     12000\n",
      "weighted avg       0.86      0.86      0.86     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_eval(y_test, pred_mlp)\n",
    "\n",
    "# 0 T-shirt/top\n",
    "# 1 Trouser\n",
    "# 2 Pullover\n",
    "# 3 Dress\n",
    "# 4 Coat\n",
    "# 5 Sandal\n",
    "# 6 Shirt\n",
    "# 7 Sneaker\n",
    "# 8 Bag\n",
    "# 9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b7b2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs/Weights:-\n",
      "\n",
      " [array([[-3.05798740e-315, -1.13123107e-119, -2.32758297e-315, ...,\n",
      "        -3.11490292e-316, -5.23677263e-316, -8.01182548e-316],\n",
      "       [ 4.64072605e-316, -2.15169013e-316,  2.74894241e-315, ...,\n",
      "        -3.79784990e-315, -2.64145597e-316,  7.28834170e-152],\n",
      "       [ 2.96939925e-316, -1.29768978e-008, -1.08563644e-315, ...,\n",
      "         3.30424951e-315, -1.55680990e-003, -1.62002392e-002],\n",
      "       ...,\n",
      "       [ 1.47349127e-315,  1.93647189e-002, -3.08998802e-002, ...,\n",
      "         2.31017611e-315, -2.97653349e-002,  1.80050360e-001],\n",
      "       [ 4.62249367e-315, -1.00335040e-002, -3.10107142e-002, ...,\n",
      "        -4.41693520e-315, -3.00191482e-002,  2.06174750e-001],\n",
      "       [ 2.57372842e-315, -3.95252137e-113,  5.56581970e-051, ...,\n",
      "        -9.74720537e-316,  7.38075709e-117,  1.22966459e-001]]), array([[ 1.60754927e-001,  8.71452636e-002,  1.51880356e-001, ...,\n",
      "         1.41381304e-001, -9.87967019e-002,  1.03463885e-001],\n",
      "       [-7.73263365e-003,  1.06057307e-128,  2.56459910e-001, ...,\n",
      "         3.63592639e-002,  2.58684523e-002, -1.50992343e-003],\n",
      "       [ 2.18554133e-002,  4.41965239e-187, -9.33451061e-002, ...,\n",
      "        -1.00916031e-001,  1.04337908e-001, -2.30586094e-002],\n",
      "       ...,\n",
      "       [-2.66576086e-219,  3.81482803e-315, -2.13772532e-175, ...,\n",
      "        -1.01148097e-315,  3.57508333e-202, -3.19371107e-188],\n",
      "       [-1.56504469e-001, -7.56651315e-002, -1.20228668e-001, ...,\n",
      "         5.02517360e-001,  9.62127554e-002, -7.39815567e-002],\n",
      "       [ 1.03164137e-001,  1.54238459e-001,  1.61630345e-001, ...,\n",
      "        -1.14837180e-001,  4.74404029e-002,  5.12976563e-002]]), array([[-0.23258387, -0.30852759, -0.00775069, ..., -0.1193079 ,\n",
      "         0.12361212,  0.06401037],\n",
      "       [-0.3182131 , -0.50246813, -0.26573647, ..., -0.06823126,\n",
      "        -0.08226541, -0.00130976],\n",
      "       [-0.31049866, -0.06976996, -0.10180371, ...,  0.15890765,\n",
      "         0.300806  ,  0.25235376],\n",
      "       ...,\n",
      "       [-0.15695642, -0.11766693, -0.24289438, ..., -0.04457289,\n",
      "         0.00618804, -0.28142431],\n",
      "       [ 0.06124783,  0.10451052,  0.09383909, ..., -0.21464983,\n",
      "        -0.20649278, -0.52721568],\n",
      "       [ 0.07327356,  0.32008264,  0.35618172, ..., -0.00630278,\n",
      "         0.26069319,  0.11856176]]), array([[ 6.56412214e-02,  1.41301622e-01,  1.28500658e-01,\n",
      "         7.58798308e-02,  5.72356844e-02, -1.86453055e-01,\n",
      "         1.07284814e-02,  5.01620528e-02,  1.74509643e-01,\n",
      "        -1.03037711e+00],\n",
      "       [ 1.48160051e-01, -1.86572322e-01,  7.21060241e-02,\n",
      "        -6.87891600e-02,  3.37236529e-02,  3.62208819e-02,\n",
      "         1.24447619e-01, -6.94580735e-02,  5.29623866e-02,\n",
      "         1.04730404e-01],\n",
      "       [ 2.45367544e-01,  1.83830975e-01, -3.54569007e-01,\n",
      "         9.64926655e-02, -3.60107431e-01, -2.11083011e-02,\n",
      "        -1.83996395e-01, -1.56249863e-01, -3.29568317e-01,\n",
      "        -7.90231482e-04],\n",
      "       [ 3.16998444e-02,  1.15018412e-01, -1.83497437e-01,\n",
      "         2.15145960e-02, -2.15799350e-01, -2.00653628e-01,\n",
      "        -1.71770948e-02, -2.59435544e-01,  1.52320461e-01,\n",
      "         4.80633850e-02],\n",
      "       [ 2.30747538e-01,  2.16593604e-01,  2.17773486e-01,\n",
      "         2.92461961e-01,  2.30135200e-01, -1.21779862e-01,\n",
      "         1.73230532e-01, -3.92850836e-01,  7.71551390e-02,\n",
      "        -1.07495816e-01],\n",
      "       [-7.34253099e-01, -1.57479652e-01, -4.06526053e-01,\n",
      "        -1.40368079e-02,  1.75949849e-01, -1.88645945e-02,\n",
      "        -2.88126067e-01,  2.66787388e-01, -1.63041280e-02,\n",
      "        -3.47266668e-01],\n",
      "       [ 1.82801238e-01, -4.81116089e-03,  8.05631029e-02,\n",
      "         9.01608744e-02, -1.28355408e-02,  3.64383339e-02,\n",
      "         1.96988727e-01, -5.81369065e-02,  4.89479430e-02,\n",
      "        -1.33031046e-02],\n",
      "       [-1.80775406e-01,  3.03689349e-01,  1.49002134e-02,\n",
      "         1.52660504e-01,  4.99527133e-02,  1.27399161e-01,\n",
      "        -5.87795095e-02,  4.58984113e-02, -1.78617559e-01,\n",
      "         2.80007783e-01],\n",
      "       [-8.03618709e-02,  5.66355891e-02, -1.70744034e-01,\n",
      "        -6.13473010e-02, -4.28500204e-02, -2.29773933e-01,\n",
      "        -3.64549831e-02, -8.02916345e-01, -1.46600769e-01,\n",
      "        -2.11631954e-01],\n",
      "       [-5.10296762e-02, -1.91017344e-01,  6.11489537e-03,\n",
      "        -5.77248259e-02, -4.30093907e-02, -1.40256198e-01,\n",
      "         2.73460575e-02, -3.13925321e-01, -1.47444723e-01,\n",
      "        -1.33919177e-01],\n",
      "       [ 1.02721507e-01, -1.70161643e-01,  2.18693607e-01,\n",
      "         7.32688675e-02,  2.07826958e-01,  5.78743830e-02,\n",
      "         1.86604190e-01, -3.22934296e-01,  4.08951464e-02,\n",
      "        -1.40232044e-01],\n",
      "       [-2.33492847e-01, -2.65718328e-02,  1.86700090e-01,\n",
      "        -8.76200380e-02,  1.66764035e-01,  1.04682582e-01,\n",
      "         8.94386788e-02, -1.44387637e-01, -4.96084006e-01,\n",
      "        -2.90856195e-01],\n",
      "       [-1.04903176e-02,  4.01583969e-02, -9.15444186e-04,\n",
      "        -1.42007046e-01, -5.00069140e-02, -6.67336063e-01,\n",
      "        -5.98763592e-02, -7.99189655e-01,  3.66018171e-02,\n",
      "        -4.56039246e-01],\n",
      "       [-2.92146062e-02, -1.19433656e-01, -2.20151131e-02,\n",
      "         6.17969174e-02, -1.56500947e-01,  1.44543091e-01,\n",
      "        -1.06013990e-01,  6.31928938e-02, -2.15595978e-01,\n",
      "         9.24628382e-02],\n",
      "       [-1.39559099e-01, -4.79934651e-01,  1.53811099e-01,\n",
      "        -6.83715685e-01, -5.44178322e-01, -8.88132716e-02,\n",
      "        -1.90727279e-01, -1.50300724e-03, -4.79897480e-01,\n",
      "        -4.10038731e-03],\n",
      "       [ 1.06741969e-01, -4.93926651e-02,  1.14311035e-01,\n",
      "         1.15907152e-01,  5.17414885e-02, -5.87435118e-01,\n",
      "         1.57499431e-01, -3.48474609e-01,  2.19572620e-01,\n",
      "        -2.90783405e-01],\n",
      "       [-5.41425428e-02,  7.68453499e-02,  4.31798765e-02,\n",
      "         1.29085025e-01,  7.83159034e-02,  8.96290722e-02,\n",
      "         1.46025342e-01, -2.34997514e-01, -6.51167320e-02,\n",
      "        -5.92460401e-01],\n",
      "       [ 6.39196421e-02,  3.31301930e-03,  1.11382165e-01,\n",
      "         1.37969036e-01,  2.21357694e-01, -1.56839974e-01,\n",
      "         1.25327617e-01, -5.19769016e-01,  1.14770653e-01,\n",
      "         1.64745944e-01],\n",
      "       [ 2.35319698e-01,  2.53450444e-01, -2.90299877e-03,\n",
      "         2.50097672e-01,  1.62523491e-01,  1.72920909e-01,\n",
      "         1.85883848e-01,  4.38652484e-02,  2.74391265e-01,\n",
      "        -7.43977516e-01],\n",
      "       [ 8.77710804e-02,  1.35126048e-01, -5.66963425e-01,\n",
      "         1.82787124e-01, -1.35093406e-01, -9.91685900e-02,\n",
      "        -1.21430768e-01, -8.33560101e-02, -9.66718144e-02,\n",
      "        -2.17221070e-02],\n",
      "       [ 6.46146265e-02, -9.75491673e-04, -1.51512100e-01,\n",
      "         1.33243891e-01, -1.49646783e-02, -1.41425608e-01,\n",
      "         2.08859902e-02, -5.13653153e-01,  1.50286100e-01,\n",
      "         2.05271017e-01],\n",
      "       [-3.75868150e-02,  5.36322060e-02, -1.30628601e-02,\n",
      "        -3.62374431e-02, -1.59075139e-01, -4.86287465e-02,\n",
      "        -1.05893967e-01, -1.55809103e-01, -2.16175548e-01,\n",
      "        -4.94205781e-02],\n",
      "       [ 2.14316096e-01, -4.35113683e-01, -3.11440346e-03,\n",
      "        -2.73790850e-02,  9.77992657e-02, -9.06916661e-02,\n",
      "         1.42554489e-01, -1.12900579e-01, -1.66315808e-01,\n",
      "        -3.71340977e-01],\n",
      "       [-1.53014441e-01, -4.00077659e-01,  5.96591336e-02,\n",
      "         1.21409987e-01, -9.75240768e-03,  1.28244658e-01,\n",
      "         2.69735810e-01,  2.27730226e-01, -1.50959676e-02,\n",
      "         5.13817837e-02],\n",
      "       [-1.15651424e-01,  2.04636750e-01, -2.76340015e-01,\n",
      "         8.38137855e-02,  5.83907357e-02,  4.37959760e-02,\n",
      "        -1.91495685e-02, -6.84282884e-02,  1.83171776e-01,\n",
      "        -1.50900913e-01],\n",
      "       [ 2.15947016e-01,  1.46058094e-01,  9.13742425e-02,\n",
      "         7.12489495e-02,  6.23741980e-02, -1.46532990e-01,\n",
      "        -2.79901102e-02, -4.86305448e-01,  1.34445078e-01,\n",
      "        -5.79087206e-02],\n",
      "       [-3.37755454e-02,  1.55074624e-01, -1.88428396e-01,\n",
      "         3.01555908e-02, -1.61505563e-01, -5.20672112e-01,\n",
      "        -2.51855013e-01, -2.77424738e-01, -5.09515110e-02,\n",
      "        -4.80443871e-01],\n",
      "       [-2.45666778e-02,  9.67997690e-02, -3.30403338e-01,\n",
      "        -3.57260400e-02, -2.94252054e-01, -1.51505282e-01,\n",
      "        -1.66065754e-01,  1.61549669e-01,  5.46925121e-02,\n",
      "         3.94629369e-02],\n",
      "       [-1.88490555e-01, -2.59582861e-01, -4.78467750e-01,\n",
      "         1.48629356e-01, -2.86935555e-01, -3.03436062e-02,\n",
      "        -6.41840978e-01, -5.46383411e-01,  6.40415539e-02,\n",
      "        -1.37152513e-01],\n",
      "       [ 2.02136114e-01,  4.68419649e-02,  7.50615395e-02,\n",
      "         1.50756144e-01,  3.23481958e-01,  3.97711919e-02,\n",
      "        -1.24884664e-01,  2.31660254e-01,  2.29781086e-01,\n",
      "         2.95529643e-01],\n",
      "       [-3.17893218e-01, -3.28942577e-01, -1.05402422e-01,\n",
      "        -2.88237306e-01, -9.52776035e-02,  3.40038444e-01,\n",
      "        -8.00336456e-02,  2.03065460e-01,  8.95782402e-02,\n",
      "        -1.33282790e-02],\n",
      "       [-1.09304537e-01, -3.44891840e-02, -2.43930451e-01,\n",
      "        -3.41418427e-01,  2.03552982e-01,  2.02262213e-01,\n",
      "        -1.63687902e-01,  1.38144111e-01, -2.92934407e-01,\n",
      "        -9.52894407e-04]])]\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Bias:-\n",
      "\n",
      " [array([-0.03735245,  0.05159363, -0.10544695, -0.07510183,  1.29155127,\n",
      "        1.07034906,  0.05024396,  1.73825518, -0.56582854,  0.41784176,\n",
      "        1.58043288, -0.03543686, -0.20019487, -0.03351625,  0.69741219,\n",
      "       -0.10945591, -0.16343365, -0.5782478 , -0.1130177 , -0.0313569 ,\n",
      "       -0.16421126,  1.68652136, -0.73870994,  0.71256427, -0.06273193,\n",
      "        0.00671742,  0.10751646, -0.00701781,  0.5230051 , -0.15347176,\n",
      "        0.07948954,  0.19680623]), array([ 1.95265805,  0.16956139,  1.20927207,  0.21484302, -0.14856186,\n",
      "       -0.60144455, -1.59773701,  0.84513006, -0.50590378,  0.28273205,\n",
      "        0.16434659, -0.12256802, -0.18965045,  0.83443178,  0.55329633,\n",
      "        1.80363131,  0.46141707, -0.08224942,  1.91736885, -0.34739022,\n",
      "        1.21579588, -0.2990086 ,  0.78627093,  0.58195302, -0.69031293,\n",
      "        0.01340311,  1.38369204,  0.74514459, -0.46133289, -1.55648513,\n",
      "       -0.42008171,  1.172386  ]), array([ 0.44165466,  1.49427081, -0.76713621, -1.68286358,  1.1315851 ,\n",
      "        0.69566   ,  1.38168305, -0.8643913 , -0.75959073,  0.90601014,\n",
      "        1.73028098, -0.39440271, -0.55446322,  0.66751939,  0.08881297,\n",
      "        0.00374035, -0.10215182,  0.25247567,  0.87607465,  0.95269402,\n",
      "        0.63379193, -1.38536512,  1.55416981,  0.87727464, -0.0750253 ,\n",
      "       -0.21319677, -0.49996139,  0.94674944, -0.07729276, -1.10644745,\n",
      "        2.63661882, -0.74821975]), array([ 0.21702143, -1.63360481, -0.4822919 ,  0.621364  , -0.48559451,\n",
      "        0.83185598,  0.681729  ,  1.29015814, -1.08992303, -1.95222027])]\n"
     ]
    }
   ],
   "source": [
    "# List all the weights used in the model\n",
    "print('Coefs/Weights:-\\n\\n',mlp.coefs_)\n",
    "print('\\n\\n\\n---------------------------------\\n\\n\\n')\n",
    "# List all the bias in the model\n",
    "print('Bias:-\\n\\n',mlp.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48c242",
   "metadata": {},
   "source": [
    "## Keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66013195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,818\n",
      "Trainable params: 167,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# activation function = 'relu' because pixels can't negative and relu take care of it, so any negative\n",
    "# value will be round-off to 0\n",
    "model.add(Dense(128, activation='relu', input_dim = 784))\n",
    "# 0.2 --> 20% of neuron will be dropped off for ensuring no overfitting\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "# Adding 128 to every layer is the bias\n",
    "# 128 * 784 + 128 = 100480 (Neruons in the 1st layer)\n",
    "# 128 * 128 + 128 = 16512 (Neruons in the 3rd layer)\n",
    "# 128 * 128 + 128 = 16512 (Neruons in the 5th layer)\n",
    "# 10 * 128 + 128 = 16512 (Neruons in the 5th layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32943733",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transform = to_categorical(y_train)\n",
    "y_test_transform = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "845ed9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train transform (48000, 10)\n",
      "y test transform (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('y train transform', y_train_transform.shape)\n",
    "print('y test transform', y_test_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3a7a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a29080ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 15:19:13.095795: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 301056000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 - 3s - loss: 2.0080 - accuracy: 0.5043 - val_loss: 0.7484 - val_accuracy: 0.7110 - 3s/epoch - 3ms/step\n",
      "Epoch 2/200\n",
      "750/750 - 2s - loss: 0.8706 - accuracy: 0.6666 - val_loss: 0.7143 - val_accuracy: 0.7135 - 2s/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "750/750 - 3s - loss: 0.7724 - accuracy: 0.6969 - val_loss: 0.6371 - val_accuracy: 0.7373 - 3s/epoch - 4ms/step\n",
      "Epoch 4/200\n",
      "750/750 - 3s - loss: 0.7137 - accuracy: 0.7086 - val_loss: 0.6247 - val_accuracy: 0.7388 - 3s/epoch - 4ms/step\n",
      "Epoch 5/200\n",
      "750/750 - 3s - loss: 0.6825 - accuracy: 0.7201 - val_loss: 0.5971 - val_accuracy: 0.7466 - 3s/epoch - 4ms/step\n",
      "Epoch 6/200\n",
      "750/750 - 2s - loss: 0.6649 - accuracy: 0.7258 - val_loss: 0.5825 - val_accuracy: 0.7527 - 2s/epoch - 3ms/step\n",
      "Epoch 7/200\n",
      "750/750 - 2s - loss: 0.6485 - accuracy: 0.7320 - val_loss: 0.5745 - val_accuracy: 0.7561 - 2s/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "750/750 - 2s - loss: 0.6456 - accuracy: 0.7353 - val_loss: 0.5868 - val_accuracy: 0.7580 - 2s/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "750/750 - 2s - loss: 0.6291 - accuracy: 0.7365 - val_loss: 0.5741 - val_accuracy: 0.7656 - 2s/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "750/750 - 2s - loss: 0.6259 - accuracy: 0.7394 - val_loss: 0.5730 - val_accuracy: 0.7628 - 2s/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "750/750 - 2s - loss: 0.6157 - accuracy: 0.7450 - val_loss: 0.5785 - val_accuracy: 0.7635 - 2s/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "750/750 - 2s - loss: 0.6089 - accuracy: 0.7498 - val_loss: 0.5749 - val_accuracy: 0.7614 - 2s/epoch - 3ms/step\n",
      "Epoch 13/200\n",
      "750/750 - 3s - loss: 0.6052 - accuracy: 0.7510 - val_loss: 0.5462 - val_accuracy: 0.7728 - 3s/epoch - 4ms/step\n",
      "Epoch 14/200\n",
      "750/750 - 2s - loss: 0.6002 - accuracy: 0.7555 - val_loss: 0.5511 - val_accuracy: 0.7772 - 2s/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "750/750 - 2s - loss: 0.5911 - accuracy: 0.7601 - val_loss: 0.5410 - val_accuracy: 0.7817 - 2s/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "750/750 - 2s - loss: 0.6008 - accuracy: 0.7576 - val_loss: 0.5352 - val_accuracy: 0.7827 - 2s/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "750/750 - 2s - loss: 0.5912 - accuracy: 0.7650 - val_loss: 0.5401 - val_accuracy: 0.7984 - 2s/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "750/750 - 2s - loss: 0.5649 - accuracy: 0.7839 - val_loss: 0.5202 - val_accuracy: 0.8148 - 2s/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "750/750 - 2s - loss: 0.5654 - accuracy: 0.7853 - val_loss: 0.5201 - val_accuracy: 0.8069 - 2s/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "750/750 - 3s - loss: 0.5687 - accuracy: 0.7901 - val_loss: 0.5071 - val_accuracy: 0.8204 - 3s/epoch - 4ms/step\n",
      "Epoch 21/200\n",
      "750/750 - 3s - loss: 0.5508 - accuracy: 0.7980 - val_loss: 0.4968 - val_accuracy: 0.8228 - 3s/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "750/750 - 2s - loss: 0.5625 - accuracy: 0.7876 - val_loss: 0.5949 - val_accuracy: 0.7755 - 2s/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "750/750 - 2s - loss: 0.5732 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.8167 - 2s/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "750/750 - 2s - loss: 0.5744 - accuracy: 0.7900 - val_loss: 0.5218 - val_accuracy: 0.8118 - 2s/epoch - 3ms/step\n",
      "Epoch 25/200\n",
      "750/750 - 2s - loss: 0.5680 - accuracy: 0.7846 - val_loss: 0.5333 - val_accuracy: 0.8054 - 2s/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "750/750 - 2s - loss: 0.5543 - accuracy: 0.7952 - val_loss: 0.4926 - val_accuracy: 0.8216 - 2s/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "750/750 - 2s - loss: 0.5423 - accuracy: 0.7981 - val_loss: 0.5143 - val_accuracy: 0.8138 - 2s/epoch - 3ms/step\n",
      "Epoch 28/200\n",
      "750/750 - 2s - loss: 0.5444 - accuracy: 0.8012 - val_loss: 0.4909 - val_accuracy: 0.8251 - 2s/epoch - 3ms/step\n",
      "Epoch 29/200\n",
      "750/750 - 3s - loss: 0.5379 - accuracy: 0.8033 - val_loss: 0.4958 - val_accuracy: 0.8174 - 3s/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "750/750 - 2s - loss: 0.5390 - accuracy: 0.8034 - val_loss: 0.5077 - val_accuracy: 0.8273 - 2s/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "750/750 - 2s - loss: 0.5271 - accuracy: 0.8068 - val_loss: 0.4897 - val_accuracy: 0.8285 - 2s/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "750/750 - 2s - loss: 0.5379 - accuracy: 0.8031 - val_loss: 0.5181 - val_accuracy: 0.8185 - 2s/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "750/750 - 2s - loss: 0.5190 - accuracy: 0.8111 - val_loss: 0.5010 - val_accuracy: 0.8191 - 2s/epoch - 3ms/step\n",
      "Epoch 34/200\n",
      "750/750 - 2s - loss: 0.5362 - accuracy: 0.8012 - val_loss: 0.4870 - val_accuracy: 0.8254 - 2s/epoch - 3ms/step\n",
      "Epoch 35/200\n",
      "750/750 - 2s - loss: 0.5256 - accuracy: 0.8064 - val_loss: 0.4952 - val_accuracy: 0.8188 - 2s/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "750/750 - 2s - loss: 0.5201 - accuracy: 0.8068 - val_loss: 0.5254 - val_accuracy: 0.7977 - 2s/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "750/750 - 2s - loss: 0.5205 - accuracy: 0.8062 - val_loss: 0.4801 - val_accuracy: 0.8321 - 2s/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "750/750 - 2s - loss: 0.5181 - accuracy: 0.8082 - val_loss: 0.4928 - val_accuracy: 0.8208 - 2s/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "750/750 - 2s - loss: 0.5428 - accuracy: 0.7856 - val_loss: 0.5493 - val_accuracy: 0.7726 - 2s/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "750/750 - 2s - loss: 0.5709 - accuracy: 0.7597 - val_loss: 0.5864 - val_accuracy: 0.7579 - 2s/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "750/750 - 2s - loss: 0.5868 - accuracy: 0.7461 - val_loss: 0.5479 - val_accuracy: 0.7535 - 2s/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "750/750 - 2s - loss: 0.5600 - accuracy: 0.7618 - val_loss: 0.5449 - val_accuracy: 0.7868 - 2s/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "750/750 - 2s - loss: 0.5709 - accuracy: 0.7660 - val_loss: 0.5222 - val_accuracy: 0.7868 - 2s/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "750/750 - 3s - loss: 0.5571 - accuracy: 0.7864 - val_loss: 0.4879 - val_accuracy: 0.8218 - 3s/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "750/750 - 2s - loss: 0.5290 - accuracy: 0.8008 - val_loss: 0.4930 - val_accuracy: 0.8193 - 2s/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "750/750 - 2s - loss: 0.5168 - accuracy: 0.8098 - val_loss: 0.5362 - val_accuracy: 0.8036 - 2s/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "750/750 - 3s - loss: 0.5181 - accuracy: 0.8061 - val_loss: 0.5357 - val_accuracy: 0.7976 - 3s/epoch - 4ms/step\n",
      "Epoch 48/200\n",
      "750/750 - 3s - loss: 0.5159 - accuracy: 0.8066 - val_loss: 0.4850 - val_accuracy: 0.8306 - 3s/epoch - 4ms/step\n",
      "Epoch 49/200\n",
      "750/750 - 2s - loss: 0.5192 - accuracy: 0.8108 - val_loss: 0.5019 - val_accuracy: 0.8286 - 2s/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "750/750 - 2s - loss: 0.5368 - accuracy: 0.7987 - val_loss: 0.4917 - val_accuracy: 0.8292 - 2s/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "750/750 - 2s - loss: 0.5124 - accuracy: 0.8080 - val_loss: 0.4962 - val_accuracy: 0.8263 - 2s/epoch - 3ms/step\n",
      "Epoch 52/200\n",
      "750/750 - 2s - loss: 0.5171 - accuracy: 0.8054 - val_loss: 0.4730 - val_accuracy: 0.8293 - 2s/epoch - 3ms/step\n",
      "Epoch 53/200\n",
      "750/750 - 2s - loss: 0.5418 - accuracy: 0.7856 - val_loss: 0.5849 - val_accuracy: 0.7638 - 2s/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "750/750 - 2s - loss: 0.5562 - accuracy: 0.7696 - val_loss: 0.5301 - val_accuracy: 0.7997 - 2s/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "750/750 - 2s - loss: 0.5143 - accuracy: 0.8080 - val_loss: 0.4981 - val_accuracy: 0.8158 - 2s/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "750/750 - 2s - loss: 0.5100 - accuracy: 0.8100 - val_loss: 0.5013 - val_accuracy: 0.8293 - 2s/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "750/750 - 2s - loss: 0.5087 - accuracy: 0.8110 - val_loss: 0.5171 - val_accuracy: 0.8240 - 2s/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "750/750 - 2s - loss: 0.5159 - accuracy: 0.8075 - val_loss: 0.5404 - val_accuracy: 0.7964 - 2s/epoch - 3ms/step\n",
      "Epoch 59/200\n",
      "750/750 - 2s - loss: 0.5363 - accuracy: 0.7827 - val_loss: 0.4915 - val_accuracy: 0.8339 - 2s/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "750/750 - 2s - loss: 0.5130 - accuracy: 0.8085 - val_loss: 0.4705 - val_accuracy: 0.8332 - 2s/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "750/750 - 2s - loss: 0.5110 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.8206 - 2s/epoch - 2ms/step\n",
      "Epoch 62/200\n",
      "750/750 - 2s - loss: 0.5050 - accuracy: 0.8080 - val_loss: 0.5088 - val_accuracy: 0.8236 - 2s/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "750/750 - 2s - loss: 0.5035 - accuracy: 0.8121 - val_loss: 0.4881 - val_accuracy: 0.8353 - 2s/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "750/750 - 2s - loss: 0.5106 - accuracy: 0.8107 - val_loss: 0.5117 - val_accuracy: 0.8250 - 2s/epoch - 2ms/step\n",
      "Epoch 65/200\n",
      "750/750 - 2s - loss: 0.5122 - accuracy: 0.8052 - val_loss: 0.4998 - val_accuracy: 0.8279 - 2s/epoch - 2ms/step\n",
      "Epoch 66/200\n",
      "750/750 - 2s - loss: 0.5170 - accuracy: 0.8091 - val_loss: 0.4935 - val_accuracy: 0.8219 - 2s/epoch - 2ms/step\n",
      "Epoch 67/200\n",
      "750/750 - 2s - loss: 0.5036 - accuracy: 0.8101 - val_loss: 0.4947 - val_accuracy: 0.8296 - 2s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "750/750 - 2s - loss: 0.5032 - accuracy: 0.8139 - val_loss: 0.4601 - val_accuracy: 0.8397 - 2s/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "750/750 - 2s - loss: 0.4899 - accuracy: 0.8201 - val_loss: 0.4666 - val_accuracy: 0.8371 - 2s/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "750/750 - 2s - loss: 0.5245 - accuracy: 0.7944 - val_loss: 0.5577 - val_accuracy: 0.7732 - 2s/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "750/750 - 2s - loss: 0.5659 - accuracy: 0.7691 - val_loss: 0.5343 - val_accuracy: 0.7787 - 2s/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "750/750 - 3s - loss: 0.5338 - accuracy: 0.7846 - val_loss: 0.5134 - val_accuracy: 0.8111 - 3s/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "750/750 - 3s - loss: 0.5180 - accuracy: 0.8025 - val_loss: 0.5058 - val_accuracy: 0.8252 - 3s/epoch - 4ms/step\n",
      "Epoch 74/200\n",
      "750/750 - 2s - loss: 0.5148 - accuracy: 0.8083 - val_loss: 0.4892 - val_accuracy: 0.8207 - 2s/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "750/750 - 2s - loss: 0.5157 - accuracy: 0.8087 - val_loss: 0.4859 - val_accuracy: 0.8363 - 2s/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "750/750 - 2s - loss: 0.4987 - accuracy: 0.8157 - val_loss: 0.4858 - val_accuracy: 0.8319 - 2s/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "750/750 - 2s - loss: 0.5042 - accuracy: 0.8164 - val_loss: 0.4847 - val_accuracy: 0.8317 - 2s/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "750/750 - 2s - loss: 0.5078 - accuracy: 0.8106 - val_loss: 0.5026 - val_accuracy: 0.8283 - 2s/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "750/750 - 2s - loss: 0.5113 - accuracy: 0.8109 - val_loss: 0.4744 - val_accuracy: 0.8372 - 2s/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "750/750 - 2s - loss: 0.5246 - accuracy: 0.8039 - val_loss: 0.5104 - val_accuracy: 0.8211 - 2s/epoch - 3ms/step\n",
      "Epoch 81/200\n",
      "750/750 - 2s - loss: 0.5074 - accuracy: 0.8077 - val_loss: 0.4735 - val_accuracy: 0.8303 - 2s/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "750/750 - 3s - loss: 0.5050 - accuracy: 0.8147 - val_loss: 0.4805 - val_accuracy: 0.8298 - 3s/epoch - 4ms/step\n",
      "Epoch 83/200\n",
      "750/750 - 2s - loss: 0.4914 - accuracy: 0.8181 - val_loss: 0.4816 - val_accuracy: 0.8373 - 2s/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "750/750 - 2s - loss: 0.4965 - accuracy: 0.8176 - val_loss: 0.4910 - val_accuracy: 0.8348 - 2s/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "750/750 - 2s - loss: 0.4857 - accuracy: 0.8231 - val_loss: 0.4917 - val_accuracy: 0.8268 - 2s/epoch - 3ms/step\n",
      "Epoch 86/200\n",
      "750/750 - 2s - loss: 0.4913 - accuracy: 0.8188 - val_loss: 0.4979 - val_accuracy: 0.8234 - 2s/epoch - 3ms/step\n",
      "Epoch 87/200\n",
      "750/750 - 2s - loss: 0.4868 - accuracy: 0.8223 - val_loss: 0.4898 - val_accuracy: 0.8126 - 2s/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "750/750 - 2s - loss: 0.4833 - accuracy: 0.8208 - val_loss: 0.5007 - val_accuracy: 0.8147 - 2s/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "750/750 - 2s - loss: 0.4935 - accuracy: 0.8172 - val_loss: 0.5114 - val_accuracy: 0.8206 - 2s/epoch - 3ms/step\n",
      "Epoch 90/200\n",
      "750/750 - 2s - loss: 0.4976 - accuracy: 0.8169 - val_loss: 0.4890 - val_accuracy: 0.8222 - 2s/epoch - 3ms/step\n",
      "Epoch 91/200\n",
      "750/750 - 2s - loss: 0.4962 - accuracy: 0.8200 - val_loss: 0.5052 - val_accuracy: 0.8200 - 2s/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "750/750 - 2s - loss: 0.4884 - accuracy: 0.8172 - val_loss: 0.4894 - val_accuracy: 0.8294 - 2s/epoch - 3ms/step\n",
      "Epoch 93/200\n",
      "750/750 - 2s - loss: 0.4803 - accuracy: 0.8206 - val_loss: 0.4780 - val_accuracy: 0.8397 - 2s/epoch - 3ms/step\n",
      "Epoch 94/200\n",
      "750/750 - 2s - loss: 0.4933 - accuracy: 0.8225 - val_loss: 0.4877 - val_accuracy: 0.8356 - 2s/epoch - 3ms/step\n",
      "Epoch 95/200\n",
      "750/750 - 2s - loss: 0.4957 - accuracy: 0.8168 - val_loss: 0.5077 - val_accuracy: 0.8232 - 2s/epoch - 3ms/step\n",
      "Epoch 96/200\n",
      "750/750 - 2s - loss: 0.5015 - accuracy: 0.8176 - val_loss: 0.5169 - val_accuracy: 0.8232 - 2s/epoch - 3ms/step\n",
      "Epoch 97/200\n",
      "750/750 - 2s - loss: 0.5012 - accuracy: 0.8172 - val_loss: 0.4895 - val_accuracy: 0.8214 - 2s/epoch - 3ms/step\n",
      "Epoch 98/200\n",
      "750/750 - 2s - loss: 0.4955 - accuracy: 0.8190 - val_loss: 0.4819 - val_accuracy: 0.8397 - 2s/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "750/750 - 2s - loss: 0.4870 - accuracy: 0.8230 - val_loss: 0.5163 - val_accuracy: 0.8179 - 2s/epoch - 3ms/step\n",
      "Epoch 100/200\n",
      "750/750 - 2s - loss: 0.4968 - accuracy: 0.8113 - val_loss: 0.5099 - val_accuracy: 0.8247 - 2s/epoch - 3ms/step\n",
      "Epoch 101/200\n",
      "750/750 - 3s - loss: 0.4961 - accuracy: 0.8164 - val_loss: 0.4991 - val_accuracy: 0.8183 - 3s/epoch - 4ms/step\n",
      "Epoch 102/200\n",
      "750/750 - 3s - loss: 0.4976 - accuracy: 0.8135 - val_loss: 0.5234 - val_accuracy: 0.8193 - 3s/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "750/750 - 2s - loss: 0.4936 - accuracy: 0.8171 - val_loss: 0.4916 - val_accuracy: 0.8352 - 2s/epoch - 3ms/step\n",
      "Epoch 104/200\n",
      "750/750 - 3s - loss: 0.5060 - accuracy: 0.8166 - val_loss: 0.4907 - val_accuracy: 0.8327 - 3s/epoch - 4ms/step\n",
      "Epoch 105/200\n",
      "750/750 - 2s - loss: 0.5107 - accuracy: 0.8151 - val_loss: 0.4788 - val_accuracy: 0.8263 - 2s/epoch - 3ms/step\n",
      "Epoch 106/200\n",
      "750/750 - 2s - loss: 0.4921 - accuracy: 0.8219 - val_loss: 0.4875 - val_accuracy: 0.8310 - 2s/epoch - 3ms/step\n",
      "Epoch 107/200\n",
      "750/750 - 2s - loss: 0.4842 - accuracy: 0.8242 - val_loss: 0.4765 - val_accuracy: 0.8386 - 2s/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "750/750 - 2s - loss: 0.4858 - accuracy: 0.8242 - val_loss: 0.4871 - val_accuracy: 0.8355 - 2s/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "750/750 - 2s - loss: 0.5013 - accuracy: 0.8213 - val_loss: 0.4925 - val_accuracy: 0.8305 - 2s/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "750/750 - 3s - loss: 0.4878 - accuracy: 0.8247 - val_loss: 0.4757 - val_accuracy: 0.8322 - 3s/epoch - 3ms/step\n",
      "Epoch 111/200\n",
      "750/750 - 2s - loss: 0.4878 - accuracy: 0.8237 - val_loss: 0.4785 - val_accuracy: 0.8364 - 2s/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "750/750 - 2s - loss: 0.4976 - accuracy: 0.8202 - val_loss: 0.5121 - val_accuracy: 0.8310 - 2s/epoch - 2ms/step\n",
      "Epoch 113/200\n",
      "750/750 - 2s - loss: 0.4845 - accuracy: 0.8224 - val_loss: 0.4786 - val_accuracy: 0.8358 - 2s/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "750/750 - 2s - loss: 0.4904 - accuracy: 0.8232 - val_loss: 0.4779 - val_accuracy: 0.8367 - 2s/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "750/750 - 2s - loss: 0.5266 - accuracy: 0.8064 - val_loss: 0.4981 - val_accuracy: 0.8121 - 2s/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "750/750 - 2s - loss: 0.4941 - accuracy: 0.8113 - val_loss: 0.5085 - val_accuracy: 0.8223 - 2s/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "750/750 - 2s - loss: 0.4790 - accuracy: 0.8260 - val_loss: 0.4926 - val_accuracy: 0.8313 - 2s/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "750/750 - 2s - loss: 0.4890 - accuracy: 0.8265 - val_loss: 0.4752 - val_accuracy: 0.8352 - 2s/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "750/750 - 2s - loss: 0.4938 - accuracy: 0.8188 - val_loss: 0.4954 - val_accuracy: 0.8307 - 2s/epoch - 2ms/step\n",
      "Epoch 120/200\n",
      "750/750 - 2s - loss: 0.4967 - accuracy: 0.8180 - val_loss: 0.5003 - val_accuracy: 0.8238 - 2s/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "750/750 - 2s - loss: 0.4922 - accuracy: 0.8173 - val_loss: 0.4797 - val_accuracy: 0.8377 - 2s/epoch - 2ms/step\n",
      "Epoch 122/200\n",
      "750/750 - 2s - loss: 0.4760 - accuracy: 0.8248 - val_loss: 0.4874 - val_accuracy: 0.8378 - 2s/epoch - 2ms/step\n",
      "Epoch 123/200\n",
      "750/750 - 2s - loss: 0.4778 - accuracy: 0.8254 - val_loss: 0.4994 - val_accuracy: 0.8335 - 2s/epoch - 2ms/step\n",
      "Epoch 124/200\n",
      "750/750 - 2s - loss: 0.4819 - accuracy: 0.8252 - val_loss: 0.4856 - val_accuracy: 0.8267 - 2s/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "750/750 - 2s - loss: 0.4843 - accuracy: 0.8265 - val_loss: 0.5696 - val_accuracy: 0.7978 - 2s/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "750/750 - 2s - loss: 0.5047 - accuracy: 0.8131 - val_loss: 0.4877 - val_accuracy: 0.8339 - 2s/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "750/750 - 2s - loss: 0.4967 - accuracy: 0.8209 - val_loss: 0.5021 - val_accuracy: 0.8306 - 2s/epoch - 3ms/step\n",
      "Epoch 128/200\n",
      "750/750 - 2s - loss: 0.4816 - accuracy: 0.8234 - val_loss: 0.4765 - val_accuracy: 0.8325 - 2s/epoch - 3ms/step\n",
      "Epoch 129/200\n",
      "750/750 - 2s - loss: 0.5047 - accuracy: 0.8144 - val_loss: 0.4929 - val_accuracy: 0.8273 - 2s/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "750/750 - 2s - loss: 0.4991 - accuracy: 0.8181 - val_loss: 0.4953 - val_accuracy: 0.8310 - 2s/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "750/750 - 2s - loss: 0.5228 - accuracy: 0.7834 - val_loss: 0.5490 - val_accuracy: 0.7832 - 2s/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "750/750 - 2s - loss: 0.5291 - accuracy: 0.7840 - val_loss: 0.5300 - val_accuracy: 0.7978 - 2s/epoch - 3ms/step\n",
      "Epoch 133/200\n",
      "750/750 - 2s - loss: 0.5210 - accuracy: 0.7910 - val_loss: 0.5249 - val_accuracy: 0.8081 - 2s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200\n",
      "750/750 - 3s - loss: 0.5012 - accuracy: 0.8000 - val_loss: 0.5152 - val_accuracy: 0.8075 - 3s/epoch - 4ms/step\n",
      "Epoch 135/200\n",
      "750/750 - 2s - loss: 0.5179 - accuracy: 0.7967 - val_loss: 0.4992 - val_accuracy: 0.8118 - 2s/epoch - 3ms/step\n",
      "Epoch 136/200\n",
      "750/750 - 2s - loss: 0.5150 - accuracy: 0.7977 - val_loss: 0.5112 - val_accuracy: 0.8155 - 2s/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "750/750 - 2s - loss: 0.4872 - accuracy: 0.8179 - val_loss: 0.5125 - val_accuracy: 0.8333 - 2s/epoch - 3ms/step\n",
      "Epoch 138/200\n",
      "750/750 - 2s - loss: 0.4851 - accuracy: 0.8201 - val_loss: 0.4727 - val_accuracy: 0.8301 - 2s/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "750/750 - 2s - loss: 0.4769 - accuracy: 0.8248 - val_loss: 0.5013 - val_accuracy: 0.8184 - 2s/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "750/750 - 2s - loss: 0.4744 - accuracy: 0.8237 - val_loss: 0.4578 - val_accuracy: 0.8391 - 2s/epoch - 3ms/step\n",
      "Epoch 141/200\n",
      "750/750 - 2s - loss: 0.4672 - accuracy: 0.8290 - val_loss: 0.5005 - val_accuracy: 0.8106 - 2s/epoch - 3ms/step\n",
      "Epoch 142/200\n",
      "750/750 - 2s - loss: 0.4683 - accuracy: 0.8305 - val_loss: 0.4692 - val_accuracy: 0.8291 - 2s/epoch - 3ms/step\n",
      "Epoch 143/200\n",
      "750/750 - 2s - loss: 0.4721 - accuracy: 0.8278 - val_loss: 0.4986 - val_accuracy: 0.8318 - 2s/epoch - 3ms/step\n",
      "Epoch 144/200\n",
      "750/750 - 2s - loss: 0.4664 - accuracy: 0.8255 - val_loss: 0.4771 - val_accuracy: 0.8229 - 2s/epoch - 3ms/step\n",
      "Epoch 145/200\n",
      "750/750 - 2s - loss: 0.4687 - accuracy: 0.8265 - val_loss: 0.4814 - val_accuracy: 0.8317 - 2s/epoch - 3ms/step\n",
      "Epoch 146/200\n",
      "750/750 - 2s - loss: 0.4781 - accuracy: 0.8262 - val_loss: 0.4833 - val_accuracy: 0.8221 - 2s/epoch - 2ms/step\n",
      "Epoch 147/200\n",
      "750/750 - 2s - loss: 0.4787 - accuracy: 0.8245 - val_loss: 0.4857 - val_accuracy: 0.8347 - 2s/epoch - 2ms/step\n",
      "Epoch 148/200\n",
      "750/750 - 2s - loss: 0.4623 - accuracy: 0.8320 - val_loss: 0.5137 - val_accuracy: 0.8042 - 2s/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "750/750 - 2s - loss: 0.4950 - accuracy: 0.8223 - val_loss: 0.5133 - val_accuracy: 0.8093 - 2s/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "750/750 - 2s - loss: 0.4883 - accuracy: 0.8170 - val_loss: 0.5008 - val_accuracy: 0.8320 - 2s/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "750/750 - 2s - loss: 0.5039 - accuracy: 0.8152 - val_loss: 0.5048 - val_accuracy: 0.8327 - 2s/epoch - 2ms/step\n",
      "Epoch 152/200\n",
      "750/750 - 2s - loss: 0.4878 - accuracy: 0.8155 - val_loss: 0.5020 - val_accuracy: 0.8298 - 2s/epoch - 2ms/step\n",
      "Epoch 153/200\n",
      "750/750 - 2s - loss: 0.5068 - accuracy: 0.8091 - val_loss: 0.4889 - val_accuracy: 0.8298 - 2s/epoch - 2ms/step\n",
      "Epoch 154/200\n",
      "750/750 - 2s - loss: 0.4803 - accuracy: 0.8214 - val_loss: 0.4961 - val_accuracy: 0.8239 - 2s/epoch - 2ms/step\n",
      "Epoch 155/200\n",
      "750/750 - 2s - loss: 0.4717 - accuracy: 0.8248 - val_loss: 0.4958 - val_accuracy: 0.8347 - 2s/epoch - 2ms/step\n",
      "Epoch 156/200\n",
      "750/750 - 2s - loss: 0.4672 - accuracy: 0.8290 - val_loss: 0.5015 - val_accuracy: 0.8322 - 2s/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "750/750 - 2s - loss: 0.5011 - accuracy: 0.8163 - val_loss: 0.5335 - val_accuracy: 0.8114 - 2s/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "750/750 - 2s - loss: 0.4916 - accuracy: 0.8180 - val_loss: 0.5271 - val_accuracy: 0.8041 - 2s/epoch - 2ms/step\n",
      "Epoch 159/200\n",
      "750/750 - 2s - loss: 0.5133 - accuracy: 0.8136 - val_loss: 0.5293 - val_accuracy: 0.8281 - 2s/epoch - 2ms/step\n",
      "Epoch 160/200\n",
      "750/750 - 2s - loss: 0.4959 - accuracy: 0.8207 - val_loss: 0.4922 - val_accuracy: 0.8331 - 2s/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "750/750 - 2s - loss: 0.4986 - accuracy: 0.8184 - val_loss: 0.5510 - val_accuracy: 0.7707 - 2s/epoch - 2ms/step\n",
      "Epoch 162/200\n",
      "750/750 - 2s - loss: 0.4754 - accuracy: 0.8214 - val_loss: 0.4925 - val_accuracy: 0.8372 - 2s/epoch - 2ms/step\n",
      "Epoch 163/200\n",
      "750/750 - 2s - loss: 0.4829 - accuracy: 0.8239 - val_loss: 0.4819 - val_accuracy: 0.8329 - 2s/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "750/750 - 2s - loss: 0.4790 - accuracy: 0.8263 - val_loss: 0.4846 - val_accuracy: 0.8364 - 2s/epoch - 2ms/step\n",
      "Epoch 165/200\n",
      "750/750 - 2s - loss: 0.4646 - accuracy: 0.8294 - val_loss: 0.5114 - val_accuracy: 0.8143 - 2s/epoch - 2ms/step\n",
      "Epoch 166/200\n",
      "750/750 - 2s - loss: 0.4782 - accuracy: 0.8184 - val_loss: 0.5140 - val_accuracy: 0.7970 - 2s/epoch - 2ms/step\n",
      "Epoch 167/200\n",
      "750/750 - 2s - loss: 0.4742 - accuracy: 0.8199 - val_loss: 0.4975 - val_accuracy: 0.8180 - 2s/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "750/750 - 2s - loss: 0.4761 - accuracy: 0.8234 - val_loss: 0.5104 - val_accuracy: 0.8242 - 2s/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "750/750 - 2s - loss: 0.4833 - accuracy: 0.8202 - val_loss: 0.4675 - val_accuracy: 0.8320 - 2s/epoch - 3ms/step\n",
      "Epoch 170/200\n",
      "750/750 - 2s - loss: 0.4681 - accuracy: 0.8283 - val_loss: 0.4626 - val_accuracy: 0.8377 - 2s/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "750/750 - 2s - loss: 0.4767 - accuracy: 0.8205 - val_loss: 0.4942 - val_accuracy: 0.8329 - 2s/epoch - 2ms/step\n",
      "Epoch 172/200\n",
      "750/750 - 2s - loss: 0.4894 - accuracy: 0.8236 - val_loss: 0.4928 - val_accuracy: 0.8215 - 2s/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "750/750 - 3s - loss: 0.4884 - accuracy: 0.8201 - val_loss: 0.4668 - val_accuracy: 0.8423 - 3s/epoch - 3ms/step\n",
      "Epoch 174/200\n",
      "750/750 - 2s - loss: 0.4792 - accuracy: 0.8266 - val_loss: 0.4924 - val_accuracy: 0.8332 - 2s/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "750/750 - 2s - loss: 0.4862 - accuracy: 0.8221 - val_loss: 0.4729 - val_accuracy: 0.8307 - 2s/epoch - 2ms/step\n",
      "Epoch 176/200\n",
      "750/750 - 2s - loss: 0.4698 - accuracy: 0.8252 - val_loss: 0.4764 - val_accuracy: 0.8374 - 2s/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "750/750 - 2s - loss: 0.4666 - accuracy: 0.8320 - val_loss: 0.4773 - val_accuracy: 0.8267 - 2s/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "750/750 - 2s - loss: 0.4933 - accuracy: 0.8184 - val_loss: 0.4903 - val_accuracy: 0.8213 - 2s/epoch - 3ms/step\n",
      "Epoch 179/200\n",
      "750/750 - 2s - loss: 0.4716 - accuracy: 0.8300 - val_loss: 0.4678 - val_accuracy: 0.8382 - 2s/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "750/750 - 2s - loss: 0.4839 - accuracy: 0.8188 - val_loss: 0.4859 - val_accuracy: 0.8248 - 2s/epoch - 2ms/step\n",
      "Epoch 181/200\n",
      "750/750 - 2s - loss: 0.4712 - accuracy: 0.8223 - val_loss: 0.4947 - val_accuracy: 0.8314 - 2s/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "750/750 - 2s - loss: 0.4630 - accuracy: 0.8313 - val_loss: 0.4655 - val_accuracy: 0.8418 - 2s/epoch - 2ms/step\n",
      "Epoch 183/200\n",
      "750/750 - 2s - loss: 0.4778 - accuracy: 0.8279 - val_loss: 0.4877 - val_accuracy: 0.8401 - 2s/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "750/750 - 2s - loss: 0.4730 - accuracy: 0.8304 - val_loss: 0.4893 - val_accuracy: 0.8390 - 2s/epoch - 3ms/step\n",
      "Epoch 185/200\n",
      "750/750 - 2s - loss: 0.4766 - accuracy: 0.8274 - val_loss: 0.4964 - val_accuracy: 0.8173 - 2s/epoch - 3ms/step\n",
      "Epoch 186/200\n",
      "750/750 - 2s - loss: 0.4830 - accuracy: 0.8261 - val_loss: 0.4799 - val_accuracy: 0.8231 - 2s/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "750/750 - 2s - loss: 0.4808 - accuracy: 0.8202 - val_loss: 0.4934 - val_accuracy: 0.8131 - 2s/epoch - 2ms/step\n",
      "Epoch 188/200\n",
      "750/750 - 2s - loss: 0.4854 - accuracy: 0.8177 - val_loss: 0.5079 - val_accuracy: 0.8181 - 2s/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "750/750 - 2s - loss: 0.4697 - accuracy: 0.8244 - val_loss: 0.4823 - val_accuracy: 0.8342 - 2s/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "750/750 - 2s - loss: 0.4630 - accuracy: 0.8290 - val_loss: 0.5246 - val_accuracy: 0.8282 - 2s/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "750/750 - 2s - loss: 0.4823 - accuracy: 0.8249 - val_loss: 0.4744 - val_accuracy: 0.8363 - 2s/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "750/750 - 2s - loss: 0.4760 - accuracy: 0.8258 - val_loss: 0.5152 - val_accuracy: 0.8235 - 2s/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "750/750 - 2s - loss: 0.4688 - accuracy: 0.8301 - val_loss: 0.5047 - val_accuracy: 0.8269 - 2s/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "750/750 - 2s - loss: 0.4584 - accuracy: 0.8341 - val_loss: 0.4912 - val_accuracy: 0.8225 - 2s/epoch - 2ms/step\n",
      "Epoch 195/200\n",
      "750/750 - 2s - loss: 0.5012 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.8266 - 2s/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "750/750 - 2s - loss: 0.4948 - accuracy: 0.8186 - val_loss: 0.5246 - val_accuracy: 0.8108 - 2s/epoch - 2ms/step\n",
      "Epoch 197/200\n",
      "750/750 - 2s - loss: 0.5046 - accuracy: 0.8170 - val_loss: 0.4880 - val_accuracy: 0.8297 - 2s/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "750/750 - 2s - loss: 0.4845 - accuracy: 0.8210 - val_loss: 0.4892 - val_accuracy: 0.8273 - 2s/epoch - 3ms/step\n",
      "Epoch 199/200\n",
      "750/750 - 2s - loss: 0.4797 - accuracy: 0.8196 - val_loss: 0.4925 - val_accuracy: 0.8284 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "750/750 - 2s - loss: 0.4732 - accuracy: 0.8240 - val_loss: 0.4845 - val_accuracy: 0.8311 - 2s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train_transform, validation_data = (X_test, y_test_transform), batch_size = 64, epochs = 200, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c658e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# pred_seq = model.predict(X_test)\n",
    "# model_eval(y_test_transform, pred_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d84c74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99583d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './content/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                                            save_weights_only = True, \n",
    "                                            monitor = 'validation_accuracy', \n",
    "                                            mode = 'max', \n",
    "                                            save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1282e1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 17:13:52.577026: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 301056000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4955 - accuracy: 0.8110 - val_loss: 0.6323 - val_accuracy: 0.8136 - 3s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5082 - accuracy: 0.8052 - val_loss: 0.6097 - val_accuracy: 0.8137 - 2s/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5120 - accuracy: 0.8016 - val_loss: 0.6285 - val_accuracy: 0.8169 - 2s/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5150 - accuracy: 0.8017 - val_loss: 0.6070 - val_accuracy: 0.8146 - 2s/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4920 - accuracy: 0.8114 - val_loss: 0.5806 - val_accuracy: 0.8187 - 3s/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.5032 - accuracy: 0.8071 - val_loss: 0.6575 - val_accuracy: 0.8139 - 3s/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4937 - accuracy: 0.8083 - val_loss: 0.6618 - val_accuracy: 0.8179 - 2s/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4911 - accuracy: 0.8105 - val_loss: 0.7066 - val_accuracy: 0.8141 - 2s/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5124 - accuracy: 0.8058 - val_loss: 0.7154 - val_accuracy: 0.8238 - 2s/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4909 - accuracy: 0.8124 - val_loss: 0.6910 - val_accuracy: 0.8148 - 2s/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4986 - accuracy: 0.7986 - val_loss: 0.7075 - val_accuracy: 0.8029 - 2s/epoch - 3ms/step\n",
      "Epoch 12/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5005 - accuracy: 0.7978 - val_loss: 0.7671 - val_accuracy: 0.8054 - 2s/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4980 - accuracy: 0.8020 - val_loss: 0.6247 - val_accuracy: 0.8056 - 2s/epoch - 3ms/step\n",
      "Epoch 14/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4954 - accuracy: 0.8004 - val_loss: 0.6806 - val_accuracy: 0.8123 - 3s/epoch - 3ms/step\n",
      "Epoch 15/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4843 - accuracy: 0.8055 - val_loss: 0.7192 - val_accuracy: 0.8098 - 2s/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4893 - accuracy: 0.8031 - val_loss: 0.6845 - val_accuracy: 0.8167 - 2s/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4995 - accuracy: 0.8096 - val_loss: 0.6759 - val_accuracy: 0.8110 - 2s/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5014 - accuracy: 0.8016 - val_loss: 0.6841 - val_accuracy: 0.8102 - 2s/epoch - 3ms/step\n",
      "Epoch 19/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5043 - accuracy: 0.8058 - val_loss: 0.6370 - val_accuracy: 0.8232 - 2s/epoch - 3ms/step\n",
      "Epoch 20/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4960 - accuracy: 0.8082 - val_loss: 0.6446 - val_accuracy: 0.8150 - 2s/epoch - 3ms/step\n",
      "Epoch 21/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5045 - accuracy: 0.8036 - val_loss: 0.6753 - val_accuracy: 0.8222 - 2s/epoch - 3ms/step\n",
      "Epoch 22/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4985 - accuracy: 0.8035 - val_loss: 0.7094 - val_accuracy: 0.8145 - 3s/epoch - 3ms/step\n",
      "Epoch 23/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4924 - accuracy: 0.8055 - val_loss: 0.6654 - val_accuracy: 0.7999 - 2s/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4961 - accuracy: 0.7997 - val_loss: 0.6850 - val_accuracy: 0.8070 - 2s/epoch - 3ms/step\n",
      "Epoch 25/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4889 - accuracy: 0.8019 - val_loss: 0.6999 - val_accuracy: 0.8097 - 3s/epoch - 3ms/step\n",
      "Epoch 26/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.5020 - accuracy: 0.7960 - val_loss: 0.6323 - val_accuracy: 0.8099 - 3s/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4990 - accuracy: 0.8010 - val_loss: 0.7432 - val_accuracy: 0.8120 - 3s/epoch - 4ms/step\n",
      "Epoch 28/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4983 - accuracy: 0.7994 - val_loss: 0.6885 - val_accuracy: 0.8118 - 2s/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4935 - accuracy: 0.8024 - val_loss: 0.6385 - val_accuracy: 0.8128 - 2s/epoch - 3ms/step\n",
      "Epoch 30/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4915 - accuracy: 0.8023 - val_loss: 0.7169 - val_accuracy: 0.8258 - 2s/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5029 - accuracy: 0.8055 - val_loss: 0.7394 - val_accuracy: 0.8145 - 2s/epoch - 3ms/step\n",
      "Epoch 32/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.5344 - accuracy: 0.7936 - val_loss: 0.6748 - val_accuracy: 0.8055 - 3s/epoch - 3ms/step\n",
      "Epoch 33/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.5199 - accuracy: 0.8012 - val_loss: 0.6321 - val_accuracy: 0.8229 - 3s/epoch - 4ms/step\n",
      "Epoch 34/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4930 - accuracy: 0.8114 - val_loss: 0.6412 - val_accuracy: 0.8120 - 2s/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4891 - accuracy: 0.8119 - val_loss: 0.6610 - val_accuracy: 0.8161 - 2s/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.5001 - accuracy: 0.8083 - val_loss: 0.6061 - val_accuracy: 0.8249 - 3s/epoch - 4ms/step\n",
      "Epoch 37/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 3s - loss: 0.4940 - accuracy: 0.8109 - val_loss: 0.6387 - val_accuracy: 0.8224 - 3s/epoch - 4ms/step\n",
      "Epoch 38/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5035 - accuracy: 0.8012 - val_loss: 0.6629 - val_accuracy: 0.8112 - 2s/epoch - 3ms/step\n",
      "Epoch 39/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4837 - accuracy: 0.8046 - val_loss: 0.6499 - val_accuracy: 0.8138 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4779 - accuracy: 0.8086 - val_loss: 0.6736 - val_accuracy: 0.7807 - 2s/epoch - 3ms/step\n",
      "Epoch 41/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5037 - accuracy: 0.8074 - val_loss: 0.6682 - val_accuracy: 0.8185 - 2s/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4928 - accuracy: 0.8118 - val_loss: 0.6694 - val_accuracy: 0.8169 - 2s/epoch - 3ms/step\n",
      "Epoch 43/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4832 - accuracy: 0.8117 - val_loss: 0.6762 - val_accuracy: 0.8136 - 2s/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5031 - accuracy: 0.8065 - val_loss: 0.6021 - val_accuracy: 0.8242 - 2s/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4770 - accuracy: 0.8142 - val_loss: 0.6313 - val_accuracy: 0.8192 - 2s/epoch - 3ms/step\n",
      "Epoch 46/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5076 - accuracy: 0.8036 - val_loss: 0.6378 - val_accuracy: 0.8177 - 2s/epoch - 3ms/step\n",
      "Epoch 47/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.5005 - accuracy: 0.8090 - val_loss: 0.6252 - val_accuracy: 0.8235 - 2s/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4961 - accuracy: 0.8102 - val_loss: 0.6888 - val_accuracy: 0.8188 - 2s/epoch - 3ms/step\n",
      "Epoch 49/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4820 - accuracy: 0.8101 - val_loss: 0.7306 - val_accuracy: 0.8271 - 2s/epoch - 3ms/step\n",
      "Epoch 50/50\n",
      "WARNING:tensorflow:Can save best model only with validation_accuracy available, skipping.\n",
      "750/750 - 2s - loss: 0.4979 - accuracy: 0.8136 - val_loss: 0.5909 - val_accuracy: 0.8275 - 2s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "hist_1 = model.fit(X_train, y_train_transform, validation_data = (X_test, y_test_transform), batch_size = 64, epochs = 50, verbose = 2, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41ff5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
